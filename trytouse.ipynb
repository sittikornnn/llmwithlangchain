{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7671d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load your local model (e.g., llama3)\n",
    "llm = Ollama(model=\"llama3.2:1b\")  # or \"mistral\" or another Ollama model\n",
    "\n",
    "# Create a simple prompt template\n",
    "template = \"What is the capital of {country}?\"\n",
    "prompt = PromptTemplate(input_variables=[\"country\"], template=template)\n",
    "\n",
    "# Create a chain that combines prompt + LLM\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Ask a question\n",
    "response = chain.run(\"France\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c10fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c581ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    return psycopg2.connect(\n",
    "        dbname='Econ',\n",
    "        user='postgres',\n",
    "        password='123456789',\n",
    "        host='localhost',\n",
    "        cursor_factory=RealDictCursor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f37e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    cursor.execute('SELECT name,price FROM public.produce ORDER BY id ASC')\n",
    "    processing = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8fbad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: vivo V50 Lite\n",
      "price: 9,999\n",
      "name: iPhone 16 Pro Max\n",
      "price: 48,900\n",
      "name: Samsung Galaxy S25 Ultra\n",
      "price: 46,900\n"
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "docs = []\n",
    "for idx, row in enumerate(data):\n",
    "    content = \"\\n\".join([f\"{key}: {value}\" for key, value in row.items()])\n",
    "    print(content)\n",
    "    docs.append(Document(page_content=content, metadata={\"row\": idx}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9069a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split text if necessary\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94faadf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'row': 0}, page_content='name: vivo V50 Lite\\nprice: 9,999'),\n",
       " Document(metadata={'row': 1}, page_content='name: iPhone 16 Pro Max\\nprice: 48,900'),\n",
       " Document(metadata={'row': 2}, page_content='name: Samsung Galaxy S25 Ultra\\nprice: 46,900')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "873f980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_15944\\986379964.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Embed documents\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0dd5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load your local Ollama model\n",
    "llm = Ollama(model=\"gemma3:4b-it-qat\")\n",
    "\n",
    "# Step 6: Set up the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9973358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š CSV QA Bot is ready! Ask a question (type 'exit' to stop):\n",
      "\n",
      "\n",
      "ðŸ§  Answer: Samsung Galaxy S25 Ultra, iPhone 16 Pro Max\n",
      "\n",
      "ðŸ“„ Rows matched: [2, 0, 1]\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ§  Answer: The vivo V50 Lite is the cheapest at 9,999.\n",
      "ðŸ“„ Rows matched: [2, 0, 1]\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ§  Answer: The iPhone 16 Pro Max is the most expensive at 48,900.\n",
      "ðŸ“„ Rows matched: [2, 0, 1]\n",
      "--------------------------------------------------\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Ask questions\n",
    "print(\"ðŸ“Š CSV QA Bot is ready! Ask a question (type 'exit' to stop):\\n\")\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"ðŸ‘‹ Goodbye!\")\n",
    "        break\n",
    "\n",
    "    result = qa_chain(query)\n",
    "    print(\"\\nðŸ§  Answer:\", result[\"result\"])\n",
    "    print(\"ðŸ“„ Rows matched:\", [doc.metadata.get(\"row\", \"unknown\") for doc in result[\"source_documents\"]])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cb29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
